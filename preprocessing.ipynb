{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bdb479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"data/train_with_transport.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03db8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=\"id\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63220d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y%m%dT%H%M%S\")\n",
    "\n",
    "df[\"year\"] = df[\"date\"].dt.year\n",
    "df[\"month\"] = df[\"date\"].dt.month\n",
    "df[\"dayofweek\"] = df[\"date\"].dt.dayofweek\n",
    "df[\"is_weekend\"] = df[\"dayofweek\"].isin([5,6]).astype(int)\n",
    "\n",
    "df.drop(columns=\"date\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_YEAR = 2015\n",
    "\n",
    "df[\"house_age\"] = CURRENT_YEAR - df[\"yr_built\"]\n",
    "df[\"renovated\"] = (df[\"yr_renovated\"] > 0).astype(int)\n",
    "df[\"quality_area\"] = df[\"sqft_living\"] * df[\"grade\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5037f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================\n",
    "# SATELLITE IMAGE EMBEDDING EXTRACTION (EfficientNet-B4)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# ===============================\n",
    "# CONFIG\n",
    "# ===============================\n",
    "IMAGE_DIR = r\"C:\\Users\\Vaibhavi\\Downloads\\CDC project\\mapbox_images_2\"\n",
    "IMAGE_SIZE = 380   # Native resolution for EfficientNet-B4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ===============================\n",
    "# LOAD EFFICIENTNET-B4 (LAST LAYER)\n",
    "# ===============================\n",
    "effnet = models.efficientnet_b4(\n",
    "    weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1\n",
    ")\n",
    "\n",
    "# Remove classifier head → keep feature extractor\n",
    "effnet.classifier = nn.Identity()\n",
    "\n",
    "effnet.to(DEVICE)\n",
    "effnet.eval()\n",
    "\n",
    "EMBED_DIM = 1792\n",
    "print(\"✅ EfficientNet-B4 loaded | Embedding dim:\", EMBED_DIM)\n",
    "\n",
    "# ===============================\n",
    "# IMAGE TRANSFORMS (IMPORTANT)\n",
    "# ===============================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# ===============================\n",
    "# IMAGE LOOKUP (ID → FILE)\n",
    "# ===============================\n",
    "image_files = {\n",
    "    f.split(\"_\")[0]: f\n",
    "    for f in os.listdir(IMAGE_DIR)\n",
    "    if f.lower().endswith(\".png\")\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# EMBEDDING FUNCTION\n",
    "# ===============================\n",
    "def extract_embedding(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = transform(img).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emb = effnet(x)  # (1, 1792)\n",
    "\n",
    "    return emb.squeeze().cpu().numpy()\n",
    "\n",
    "# ===============================\n",
    "# MAIN EXTRACTION LOOP\n",
    "# ===============================\n",
    "rows = []\n",
    "\n",
    "for pid in tqdm(df[\"id\"].astype(str), desc=\"Extracting EfficientNet-B4 embeddings\"):\n",
    "    if pid not in image_files:\n",
    "        continue\n",
    "\n",
    "    img_path = os.path.join(IMAGE_DIR, image_files[pid])\n",
    "    embedding = extract_embedding(img_path)\n",
    "\n",
    "    row = {\"id\": pid}\n",
    "    for i, val in enumerate(embedding):\n",
    "        row[f\"img_{i}\"] = val\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "img_emb_df = pd.DataFrame(rows)\n",
    "\n",
    "print(\"✅ EfficientNet-B4 embeddings extracted\")\n",
    "print(\"Shape:\", img_emb_df.shape)\n",
    "df.to_csv(\"data/final_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b83ada",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# ---------- TOP-25 FEATURE IMPORTANCE (HORIZONTAL BARPLOT) ----------\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TOP_K = 25\n",
    "\n",
    "# Feature names (same order as training)\n",
    "feature_names = multimodal_features\n",
    "\n",
    "# Extract gain-based importance from XGBoost\n",
    "booster = best_model.get_booster()\n",
    "importance_dict = booster.get_score(importance_type=\"gain\")\n",
    "\n",
    "# Build importance DataFrame\n",
    "imp_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": [importance_dict.get(f\"f{i}\", 0.0) for i in range(len(feature_names))]\n",
    "})\n",
    "\n",
    "# Keep only non-zero importance features\n",
    "imp_df = imp_df[imp_df[\"importance\"] > 0]\n",
    "\n",
    "# Select top-25 features\n",
    "imp_df = imp_df.sort_values(\"importance\", ascending=False).head(TOP_K)\n",
    "\n",
    "# Re-sort for horizontal plotting (small → large)\n",
    "imp_df = imp_df.sort_values(\"importance\", ascending=True)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.barh(imp_df[\"feature\"], imp_df[\"importance\"])\n",
    "plt.xlabel(\"Feature Importance (Gain)\")\n",
    "plt.title(\"Top 25 Feature Importances — Multimodal XGBoost\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3793bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='dist_to_metro_m',y='price',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1aa31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='dist_to_railway_m',y='price',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50a650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='dist_to_airport_m',y='price',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa2fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='waterfront',y='price',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4662cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='grade',y='price',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14,5))\n",
    "\n",
    "sns.histplot(df['price'], bins=50, kde=True, ax=axes[0])\n",
    "axes[0].set_title(\"Raw Price Distribution\")\n",
    "\n",
    "sns.histplot(np.log(df['price']), bins=50, kde=True, ax=axes[1])\n",
    "axes[1].set_title(\"Log-Transformed Price Distribution\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be484f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# COMPLETE, UPDATED & CORRECTED GRAD-CAM (SIDE-BY-SIDE VIEW)\n",
    "# EfficientNet-B4 | Original Image + Grad-CAM Overlay\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "# ===============================\n",
    "# CONFIG\n",
    "# ===============================\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "# ===============================\n",
    "# LOAD EFFICIENTNET-B4 (FEATURE EXTRACTOR)\n",
    "# ===============================\n",
    "effnet = models.efficientnet_b4(\n",
    "    weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1\n",
    ")\n",
    "effnet.classifier = nn.Identity()   # remove FC head\n",
    "effnet.to(DEVICE)\n",
    "effnet.eval()\n",
    "\n",
    "# ===============================\n",
    "# IMAGE TRANSFORM\n",
    "# ===============================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# ===============================\n",
    "# GRAD-CAM CLASS\n",
    "# ===============================\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output.detach()\n",
    "\n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            self.gradients = grad_output[0].detach()\n",
    "\n",
    "        self.target_layer.register_forward_hook(forward_hook)\n",
    "        self.target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    def generate(self, input_tensor):\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        output = self.model(input_tensor)   # (1, 1792)\n",
    "        score = output.mean()               # scalar for Grad-CAM\n",
    "        score.backward()\n",
    "\n",
    "        weights = self.gradients.mean(dim=(2, 3), keepdim=True)\n",
    "        cam = (weights * self.activations).sum(dim=1)\n",
    "\n",
    "        cam = torch.relu(cam)\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / (cam.max() + 1e-8)\n",
    "\n",
    "        return cam.squeeze().cpu().numpy()\n",
    "\n",
    "# ===============================\n",
    "# INITIALIZE GRAD-CAM\n",
    "# (use -3 for better spatial resolution)\n",
    "# ===============================\n",
    "target_layer = effnet.features[-3]\n",
    "gradcam = GradCAM(effnet, target_layer)\n",
    "\n",
    "# ===============================\n",
    "# SIDE-BY-SIDE VISUALIZATION\n",
    "# ===============================\n",
    "def show_side_by_side_gradcam(img_path):\n",
    "    # Load original image\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Prepare input\n",
    "    input_tensor = transform(img).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    # Generate CAM\n",
    "    cam = gradcam.generate(input_tensor)\n",
    "\n",
    "    # Resize CAM to image size\n",
    "    cam_resized = cv2.resize(\n",
    "        cam,\n",
    "        (img_np.shape[1], img_np.shape[0]),\n",
    "        interpolation=cv2.INTER_CUBIC\n",
    "    )\n",
    "\n",
    "    # Smooth CAM\n",
    "    cam_resized = cv2.GaussianBlur(cam_resized, (31, 31), 0)\n",
    "\n",
    "    # Heatmap\n",
    "    heatmap = cv2.applyColorMap(\n",
    "        np.uint8(255 * cam_resized),\n",
    "        cv2.COLORMAP_JET\n",
    "    )\n",
    "\n",
    "    # Overlay\n",
    "    overlay = cv2.addWeighted(\n",
    "        img_np, 0.65,\n",
    "        heatmap, 0.35,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    # Plot side-by-side\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(\"Original Satellite Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(overlay)\n",
    "    plt.title(\"Grad-CAM: Visual Drivers of Price\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ===============================\n",
    "# RUN (EXAMPLE)\n",
    "# ===============================\n",
    "show_side_by_side_gradcam(r\"C:\\Users\\Vaibhavi\\Downloads\\CDC project\\mapbox_images_2\\11500890_z18_s2.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
